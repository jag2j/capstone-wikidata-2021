{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone: Wikidata\n",
    "## Separate Entity-property-entity and Entity-property-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set size of chunk to read in\n",
    "BUFSIZE= 10**9\n",
    "\n",
    "# flag to stop early\n",
    "STOPEARLY = False\n",
    "STOPCOUNT = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 1\n",
      "Chunk: 2\n",
      "Chunk: 3\n",
      "Chunk: 4\n",
      "Chunk: 5\n",
      "Chunk: 6\n",
      "Chunk: 7\n",
      "Chunk: 8\n",
      "Chunk: 9\n",
      "Chunk: 10\n",
      "Chunk: 11\n",
      "Chunk: 12\n",
      "Chunk: 13\n",
      "Chunk: 14\n",
      "Chunk: 15\n",
      "Chunk: 16\n",
      "Chunk: 17\n",
      "Chunk: 18\n",
      "Chunk: 19\n",
      "Chunk: 20\n",
      "Chunk: 21\n",
      "Chunk: 22\n",
      "Chunk: 23\n",
      "Chunk: 24\n",
      "Chunk: 25\n",
      "Chunk: 26\n",
      "Chunk: 27\n",
      "Chunk: 28\n",
      "Chunk: 29\n",
      "Chunk: 30\n",
      "Chunk: 31\n",
      "Chunk: 32\n",
      "Chunk: 33\n",
      "Chunk: 34\n",
      "Chunk: 35\n",
      "Chunk: 36\n",
      "Chunk: 37\n",
      "Chunk: 38\n",
      "Chunk: 39\n",
      "Chunk: 40\n",
      "Chunk: 41\n",
      "Chunk: 42\n",
      "Chunk: 43\n",
      "Chunk: 44\n",
      "Chunk: 45\n",
      "Chunk: 46\n",
      "Chunk: 47\n",
      "Chunk: 48\n",
      "Chunk: 49\n",
      "Chunk: 50\n",
      "Chunk: 51\n",
      "Chunk: 52\n",
      "Chunk: 53\n",
      "Chunk: 54\n",
      "Chunk: 55\n",
      "Chunk: 56\n",
      "Chunk: 57\n",
      "Chunk: 58\n",
      "Chunk: 59\n",
      "Chunk: 60\n",
      "Chunk: 61\n",
      "Chunk: 62\n",
      "Chunk: 63\n",
      "Chunk: 64\n",
      "Chunk: 65\n",
      "Chunk: 66\n",
      "Chunk: 67\n",
      "Chunk: 68\n",
      "Chunk: 69\n",
      "Chunk: 70\n",
      "Chunk: 71\n",
      "Chunk: 72\n",
      "Chunk: 73\n",
      "Chunk: 74\n",
      "Chunk: 75\n",
      "Chunk: 76\n",
      "Chunk: 77\n",
      "Chunk: 78\n",
      "Chunk: 79\n",
      "Chunk: 80\n",
      "Chunk: 81\n",
      "Chunk: 82\n",
      "Chunk: 83\n",
      "Chunk: 84\n",
      "Chunk: 85\n",
      "Chunk: 86\n",
      "Chunk: 87\n",
      "Chunk: 88\n",
      "Chunk: 89\n",
      "Chunk: 90\n",
      "Chunk: 91\n",
      "Chunk: 92\n",
      "Chunk: 93\n",
      "Chunk: 94\n",
      "Chunk: 95\n",
      "Chunk: 96\n",
      "Chunk: 97\n",
      "Chunk: 98\n",
      "Chunk: 99\n",
      "Chunk: 100\n",
      "Chunk: 101\n",
      "Chunk: 102\n",
      "Chunk: 103\n",
      "Chunk: 104\n",
      "Chunk: 105\n",
      "Chunk: 106\n",
      "Chunk: 107\n",
      "Chunk: 108\n",
      "Chunk: 109\n",
      "Chunk: 110\n",
      "Chunk: 111\n",
      "Chunk: 112\n",
      "Chunk: 113\n",
      "Chunk: 114\n",
      "Chunk: 115\n",
      "Chunk: 116\n",
      "Chunk: 117\n",
      "Chunk: 118\n",
      "Chunk: 119\n",
      "Chunk: 120\n",
      "Chunk: 121\n",
      "Chunk: 122\n",
      "Chunk: 123\n",
      "Chunk: 124\n",
      "Chunk: 125\n",
      "Chunk: 126\n",
      "Chunk: 127\n",
      "Chunk: 128\n",
      "Chunk: 129\n",
      "Chunk: 130\n",
      "Chunk: 131\n",
      "Chunk: 132\n",
      "Chunk: 133\n",
      "Chunk: 134\n",
      "Chunk: 135\n",
      "Chunk: 136\n",
      "Chunk: 137\n",
      "Chunk: 138\n",
      "Chunk: 139\n",
      "Chunk: 140\n",
      "Chunk: 141\n",
      "Chunk: 142\n",
      "Chunk: 143\n",
      "Chunk: 144\n",
      "Chunk: 145\n",
      "Chunk: 146\n",
      "Chunk: 147\n",
      "Chunk: 148\n",
      "Chunk: 149\n",
      "Chunk: 150\n",
      "Chunk: 151\n",
      "Chunk: 152\n",
      "Chunk: 153\n",
      "Chunk: 154\n",
      "Chunk: 155\n",
      "Chunk: 156\n",
      "Chunk: 157\n",
      "Chunk: 158\n",
      "Chunk: 159\n",
      "Chunk: 160\n",
      "Chunk: 161\n",
      "Chunk: 162\n",
      "Chunk: 163\n",
      "Chunk: 164\n",
      "Chunk: 165\n",
      "Chunk: 166\n",
      "Chunk: 167\n",
      "Chunk: 168\n",
      "Chunk: 169\n",
      "Chunk: 170\n",
      "Chunk: 171\n",
      "Chunk: 172\n",
      "Chunk: 173\n",
      "Chunk: 174\n",
      "Chunk: 175\n",
      "Chunk: 176\n",
      "Chunk: 177\n",
      "Chunk: 178\n",
      "Chunk: 179\n",
      "Chunk: 180\n",
      "Chunk: 181\n",
      "Chunk: 182\n",
      "Chunk: 183\n",
      "Chunk: 184\n",
      "Chunk: 185\n",
      "Chunk: 186\n",
      "Chunk: 187\n",
      "Chunk: 188\n",
      "Chunk: 189\n",
      "Chunk: 190\n",
      "Chunk: 191\n",
      "Chunk: 192\n",
      "Chunk: 193\n",
      "Chunk: 194\n",
      "Chunk: 195\n",
      "Chunk: 196\n",
      "Chunk: 197\n",
      "Chunk: 198\n",
      "Chunk: 199\n",
      "Chunk: 200\n",
      "Chunk: 201\n",
      "Chunk: 202\n",
      "Chunk: 203\n",
      "Size in memory 0.0GB\n",
      "CPU times: user 1h 42min 58s, sys: 7min 2s, total: 1h 50min\n",
      "Wall time: 1h 56min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# open truth-NT file\n",
    "fin = open(\"/scratch/trh6u/WD_entity_lines.nt\",\"r\")\n",
    "\n",
    "# open output file\n",
    "fout_epe = open(\"/scratch/trh6u/WD_entity_prop_entity.csv\",\"w\")\n",
    "fout_epv = open(\"/scratch/trh6u/WD_entity_prop_value.csv\",\"w\")\n",
    "fout_elv = open(\"/scratch/trh6u/WD_entity_label_value.csv\",\"w\")\n",
    "\n",
    "# read in first chunk\n",
    "lines = fin.readlines(BUFSIZE)\n",
    "\n",
    "# count for stopping early\n",
    "chunk_count = 1\n",
    "\n",
    "# total size in memory\n",
    "total_size = 0\n",
    "\n",
    "def separate_nt(line):\n",
    "    nt1 = line.split(\" \")[0]\n",
    "    nt2 = line.split(\" \")[1]\n",
    "    nt3 = line.split(\" \")[2]\n",
    "\n",
    "    return nt1, nt2, nt3\n",
    "    \n",
    "def process_epe(nt1, nt2, nt3):\n",
    "    entity1 = nt1.split(\"/\")[-1]\n",
    "    prop = nt2.split(\"/\")[-1]\n",
    "    entity2 = nt3.split(\"/\")[-1]\n",
    "    \n",
    "    entity1 = entity1.replace(\"Q\",\"\").replace(\">\",\"\")\n",
    "    entity2 = entity2.replace(\"Q\",\"\").replace(\">\",\"\")\n",
    "    prop = prop.replace(\"P\",\"\").replace(\">\",\"\")\n",
    "    \n",
    "    return entity1 + \",\" + prop + \",\" + entity2 + \"\\n\"\n",
    "    \n",
    "def process_epv(nt1, nt2, nt3):\n",
    "    entity = nt1.split(\"/\")[-1]\n",
    "    prop = nt2.split(\"/\")[-1]\n",
    "    value = nt3\n",
    "    \n",
    "    entity = entity.replace(\"Q\",\"\").replace(\">\",\"\")\n",
    "    prop = prop.replace(\"P\",\"\").replace(\">\",\"\")\n",
    "    value = value.replace(\"<\",\"\").replace(\">\",\"\")\n",
    "    \n",
    "    return entity + \",\" + prop + \",\" + value + \"\\n\"\n",
    "\n",
    "def process_elv(nt1, nt2, nt3):\n",
    "    entity = nt1.split(\"/\")[-1]\n",
    "    label = nt2\n",
    "    value = nt3\n",
    "    \n",
    "    entity = entity.replace(\"Q\",\"\").replace(\">\",\"\")\n",
    "    label = label.replace(\"<\",\"\").replace(\">\",\"\")\n",
    "    value = value.replace(\"<\",\"\").replace(\">\",\"\")\n",
    "    \n",
    "    return entity + \",\" + label + \",\" + value + \"\\n\"\n",
    "\n",
    "# regex for values\n",
    "qregex = re.compile(\"Q[0-9]+>$\")\n",
    "pregex = re.compile(\"P[0-9]+>$\")\n",
    "\n",
    "# while more data to read in\n",
    "while lines:\n",
    "    print(f\"Chunk: {chunk_count}\")\n",
    "       \n",
    "    # loop through lines\n",
    "    for line in lines:    \n",
    "        #print(line)\n",
    "        \n",
    "        # separate terms in triple\n",
    "        nt1,nt2,nt3 = separate_nt(line)\n",
    "        \n",
    "        # if middle term is a property\n",
    "        if pregex.search(nt2):\n",
    "            \n",
    "            # if last term is a entity\n",
    "            if qregex.search(nt3):\n",
    "                        \n",
    "                # process E-P-E and store\n",
    "                epe_csv = process_epe(nt1, nt2, nt3)\n",
    "                #print(\"EPE: \", epe_csv)\n",
    "                fout_epe.write(epe_csv)\n",
    "            else:\n",
    "                \n",
    "                # process E-P-V and store\n",
    "                epv_csv = process_epv(nt1, nt2, nt3)\n",
    "                #print(\"EPV: \", epv_csv)\n",
    "                fout_epv.write(epv_csv)\n",
    "                \n",
    "        # else middle term is not a proptery\n",
    "        else:\n",
    "            # process E-L-V and store\n",
    "            elv_csv = process_elv(nt1, nt2, nt3)\n",
    "            #print(\"ELV: \", elv_csv)\n",
    "            fout_elv.write(elv_csv)  \n",
    "            \n",
    "    # check if we want to terminate before \n",
    "    if STOPEARLY & (chunk_count>=STOPCOUNT):\n",
    "        break\n",
    "    \n",
    "    # read next data chunk\n",
    "    lines = fin.readlines(BUFSIZE)\n",
    "    \n",
    "    # increment count\n",
    "    chunk_count += 1\n",
    "\n",
    "print(f\"Size in memory {total_size/10**9}GB\")\n",
    "    \n",
    "fin.close()\n",
    "fout_epe.close()\n",
    "fout_epv.close()\n",
    "fout_elv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
